{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "from scipy.misc import imread "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#changing the working directory\n",
    "\n",
    "os.chdir(\"E:\\\\AV\\\\case study\\\\mnist - unsupervised deep learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train\\\\train\\\\train.csv\")\n",
    "test = pd.read_csv(\"Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18e57450208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting of an image\n",
    "\n",
    "img_name = rng.choice(train.filename)\n",
    "\n",
    "filepath = os.path.join('E:\\\\AV\\\\case study\\\\mnist - unsupervised deep learning\\\\Train\\\\Train\\\\Images','train',img_name)\n",
    "img = imread(filepath,flatten=True)\n",
    "\n",
    "pylab.imshow(img,cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading all the images and converting them to a numpy array\n",
    "\n",
    "temp =[]\n",
    "\n",
    "for img_name in train.filename:\n",
    "    filepath = os.path.join('E:\\\\AV\\\\case study\\\\mnist - unsupervised deep learning\\\\Train\\\\Train\\\\Images','train',img_name)\n",
    "    img = imread(filepath,flatten=True)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = np.stack(temp)\n",
    "train_x/= 255.0\n",
    "train_x = train_x.reshape(-1,784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 784)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#similarly for test data\n",
    "\n",
    "temp =[]\n",
    "\n",
    "for img_name in test.filename:\n",
    "    filepath = os.path.join('E:\\\\AV\\\\case study\\\\mnist - unsupervised deep learning\\\\Train\\\\Train\\\\Images','test',img_name)\n",
    "    img = imread(filepath,flatten=True)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    "\n",
    "test_x = np.stack(temp)\n",
    "test_x/= 255.0\n",
    "test_x = test_x.reshape(-1,784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the train into validation and train\n",
    "\n",
    "split = int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x,val_x = train_x[:split],train_x[split:]\n",
    "train_y,val_y = train_y[:split],train_y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "from keras.models import Model,Sequential\n",
    "from keras.optimizers import sgd\n",
    "from keras.layers import Dense,Input,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# implementing auto encoder\n",
    "\n",
    "#this is input plaeholder\n",
    "input_img = Input(shape=(784,))\n",
    "corrupt_img = Dropout(0.5)(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoded\n",
    "\n",
    "encoded = Dense(500,activation='relu')(corrupt_img)\n",
    "encoded = Dense(500,activation='relu')(encoded)\n",
    "encoded = Dense(2000,activation='relu')(encoded)\n",
    "encoded = Dense(10,activation='sigmoid')(encoded)\n",
    "\n",
    "#decoded\n",
    "\n",
    "decoded = Dense(2000,activation='relu')(encoded)\n",
    "decoded = Dense(500,activation='relu')(decoded)\n",
    "decoded = Dense(500,activation='relu')(decoded)\n",
    "decoded = Dense(784)(decoded)\n",
    "\n",
    "#model to map an input to its reconstruction\n",
    "\n",
    "autoencoder = Model(input_img,decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2000)              1002000   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                20010     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2000)              22000     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               1000500   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 784)               392784    \n",
      "=================================================================\n",
      "Total params: 3,330,794\n",
      "Trainable params: 3,330,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0786 - val_loss: 0.0660\n",
      "Epoch 2/100\n",
      "34300/34300 [==============================] - 33s - loss: 0.0650 - val_loss: 0.0651\n",
      "Epoch 3/100\n",
      "34300/34300 [==============================] - 37s - loss: 0.0635 - val_loss: 0.0625\n",
      "Epoch 4/100\n",
      "34300/34300 [==============================] - 33s - loss: 0.0603 - val_loss: 0.0612\n",
      "Epoch 5/100\n",
      "34300/34300 [==============================] - 35s - loss: 0.0578 - val_loss: 0.0592\n",
      "Epoch 6/100\n",
      "34300/34300 [==============================] - 40s - loss: 0.0564 - val_loss: 0.0574\n",
      "Epoch 7/100\n",
      "34300/34300 [==============================] - 41s - loss: 0.0551 - val_loss: 0.0557\n",
      "Epoch 8/100\n",
      "34300/34300 [==============================] - 40s - loss: 0.0527 - val_loss: 0.0537\n",
      "Epoch 9/100\n",
      "34300/34300 [==============================] - 40s - loss: 0.0489 - val_loss: 0.0469\n",
      "Epoch 10/100\n",
      "34300/34300 [==============================] - 40s - loss: 0.0446 - val_loss: 0.0426\n",
      "Epoch 11/100\n",
      "34300/34300 [==============================] - 41s - loss: 0.0402 - val_loss: 0.0390\n",
      "Epoch 12/100\n",
      "34300/34300 [==============================] - 35s - loss: 0.0375 - val_loss: 0.0367\n",
      "Epoch 13/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0358 - val_loss: 0.0353\n",
      "Epoch 14/100\n",
      "34300/34300 [==============================] - 36s - loss: 0.0344 - val_loss: 0.0338\n",
      "Epoch 15/100\n",
      "34300/34300 [==============================] - 35s - loss: 0.0331 - val_loss: 0.0317\n",
      "Epoch 16/100\n",
      "34300/34300 [==============================] - 35s - loss: 0.0321 - val_loss: 0.0313\n",
      "Epoch 17/100\n",
      "34300/34300 [==============================] - 36s - loss: 0.0312 - val_loss: 0.0308\n",
      "Epoch 18/100\n",
      "34300/34300 [==============================] - 41s - loss: 0.0304 - val_loss: 0.0297\n",
      "Epoch 19/100\n",
      "34300/34300 [==============================] - 41s - loss: 0.0298 - val_loss: 0.0290\n",
      "Epoch 20/100\n",
      "34300/34300 [==============================] - 42s - loss: 0.0291 - val_loss: 0.0283\n",
      "Epoch 21/100\n",
      "34300/34300 [==============================] - 42s - loss: 0.0285 - val_loss: 0.0282\n",
      "Epoch 22/100\n",
      "34300/34300 [==============================] - 40s - loss: 0.0281 - val_loss: 0.0278\n",
      "Epoch 23/100\n",
      "34300/34300 [==============================] - 46s - loss: 0.0275 - val_loss: 0.0268\n",
      "Epoch 24/100\n",
      "34300/34300 [==============================] - 45s - loss: 0.0270 - val_loss: 0.0260\n",
      "Epoch 25/100\n",
      "34300/34300 [==============================] - 41s - loss: 0.0268 - val_loss: 0.0250\n",
      "Epoch 26/100\n",
      "34300/34300 [==============================] - 40s - loss: 0.0263 - val_loss: 0.0251\n",
      "Epoch 27/100\n",
      "34300/34300 [==============================] - 39s - loss: 0.0258 - val_loss: 0.0247\n",
      "Epoch 28/100\n",
      "34300/34300 [==============================] - 40s - loss: 0.0256 - val_loss: 0.0249\n",
      "Epoch 29/100\n",
      "34300/34300 [==============================] - 42s - loss: 0.0253 - val_loss: 0.0245\n",
      "Epoch 30/100\n",
      "34300/34300 [==============================] - 40s - loss: 0.0248 - val_loss: 0.0239\n",
      "Epoch 31/100\n",
      "34300/34300 [==============================] - 42s - loss: 0.0246 - val_loss: 0.0237\n",
      "Epoch 32/100\n",
      "34300/34300 [==============================] - 43s - loss: 0.0243 - val_loss: 0.0231\n",
      "Epoch 33/100\n",
      "34300/34300 [==============================] - 42s - loss: 0.0241 - val_loss: 0.0233\n",
      "Epoch 34/100\n",
      "34300/34300 [==============================] - 35s - loss: 0.0238 - val_loss: 0.0226\n",
      "Epoch 35/100\n",
      "34300/34300 [==============================] - 46s - loss: 0.0236 - val_loss: 0.0226\n",
      "Epoch 36/100\n",
      "34300/34300 [==============================] - 40s - loss: 0.0233 - val_loss: 0.0222\n",
      "Epoch 37/100\n",
      "34300/34300 [==============================] - 41s - loss: 0.0231 - val_loss: 0.0221\n",
      "Epoch 38/100\n",
      "34300/34300 [==============================] - 41s - loss: 0.0231 - val_loss: 0.0223\n",
      "Epoch 39/100\n",
      "34300/34300 [==============================] - 45s - loss: 0.0228 - val_loss: 0.0218\n",
      "Epoch 40/100\n",
      "34300/34300 [==============================] - 41s - loss: 0.0226 - val_loss: 0.0217\n",
      "Epoch 41/100\n",
      "34300/34300 [==============================] - 40s - loss: 0.0225 - val_loss: 0.0216\n",
      "Epoch 42/100\n",
      "34300/34300 [==============================] - 41s - loss: 0.0223 - val_loss: 0.0214\n",
      "Epoch 43/100\n",
      "34300/34300 [==============================] - 42s - loss: 0.0221 - val_loss: 0.0213\n",
      "Epoch 44/100\n",
      "34300/34300 [==============================] - 42s - loss: 0.0221 - val_loss: 0.0214\n",
      "Epoch 45/100\n",
      "34300/34300 [==============================] - 41s - loss: 0.0219 - val_loss: 0.0211\n",
      "Epoch 46/100\n",
      "34300/34300 [==============================] - 42s - loss: 0.0218 - val_loss: 0.0211\n",
      "Epoch 47/100\n",
      "34300/34300 [==============================] - 44s - loss: 0.0217 - val_loss: 0.0209\n",
      "Epoch 48/100\n",
      "34300/34300 [==============================] - 42s - loss: 0.0215 - val_loss: 0.0205\n",
      "Epoch 49/100\n",
      "34300/34300 [==============================] - 35s - loss: 0.0214 - val_loss: 0.0202\n",
      "Epoch 50/100\n",
      "34300/34300 [==============================] - 38s - loss: 0.0213 - val_loss: 0.0203\n",
      "Epoch 51/100\n",
      "34300/34300 [==============================] - 41s - loss: 0.0212 - val_loss: 0.0202\n",
      "Epoch 52/100\n",
      "34300/34300 [==============================] - 39s - loss: 0.0212 - val_loss: 0.0206\n",
      "Epoch 53/100\n",
      "34300/34300 [==============================] - 36s - loss: 0.0210 - val_loss: 0.0200\n",
      "Epoch 54/100\n",
      "34300/34300 [==============================] - 35s - loss: 0.0209 - val_loss: 0.0199\n",
      "Epoch 55/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0207 - val_loss: 0.0198\n",
      "Epoch 56/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0207 - val_loss: 0.0202\n",
      "Epoch 57/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0206 - val_loss: 0.0198\n",
      "Epoch 58/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0205 - val_loss: 0.0196\n",
      "Epoch 59/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0204 - val_loss: 0.0195\n",
      "Epoch 60/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0203 - val_loss: 0.0196\n",
      "Epoch 61/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0202 - val_loss: 0.0194\n",
      "Epoch 62/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0201 - val_loss: 0.0198\n",
      "Epoch 63/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0201 - val_loss: 0.0193\n",
      "Epoch 64/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0200 - val_loss: 0.0195\n",
      "Epoch 65/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0200 - val_loss: 0.0192\n",
      "Epoch 66/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0198 - val_loss: 0.0190\n",
      "Epoch 67/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0198 - val_loss: 0.0189\n",
      "Epoch 68/100\n",
      "34300/34300 [==============================] - 35s - loss: 0.0197 - val_loss: 0.0188\n",
      "Epoch 69/100\n",
      "34300/34300 [==============================] - 35s - loss: 0.0196 - val_loss: 0.0189\n",
      "Epoch 70/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0196 - val_loss: 0.0189\n",
      "Epoch 71/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0195 - val_loss: 0.0189\n",
      "Epoch 72/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0195 - val_loss: 0.0187\n",
      "Epoch 73/100\n",
      "34300/34300 [==============================] - 36s - loss: 0.0194 - val_loss: 0.0187\n",
      "Epoch 74/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0194 - val_loss: 0.0184\n",
      "Epoch 75/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0193 - val_loss: 0.0184\n",
      "Epoch 76/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0192 - val_loss: 0.0183\n",
      "Epoch 77/100\n",
      "34300/34300 [==============================] - 32s - loss: 0.0192 - val_loss: 0.0185\n",
      "Epoch 78/100\n",
      "34300/34300 [==============================] - 32s - loss: 0.0191 - val_loss: 0.0182\n",
      "Epoch 79/100\n",
      "34300/34300 [==============================] - 31s - loss: 0.0190 - val_loss: 0.0183\n",
      "Epoch 80/100\n",
      "34300/34300 [==============================] - 32s - loss: 0.0190 - val_loss: 0.0181\n",
      "Epoch 81/100\n",
      "34300/34300 [==============================] - 32s - loss: 0.0189 - val_loss: 0.0183\n",
      "Epoch 82/100\n",
      "34300/34300 [==============================] - 33s - loss: 0.0188 - val_loss: 0.0180\n",
      "Epoch 83/100\n",
      "34300/34300 [==============================] - 34s - loss: 0.0188 - val_loss: 0.0182\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34300/34300 [==============================] - 35s - loss: 0.0189 - val_loss: 0.0179\n",
      "Epoch 85/100\n",
      "34300/34300 [==============================] - 33s - loss: 0.0187 - val_loss: 0.0180\n",
      "Epoch 86/100\n",
      "34300/34300 [==============================] - 32s - loss: 0.0187 - val_loss: 0.0183\n",
      "Epoch 87/100\n",
      "34300/34300 [==============================] - 32s - loss: 0.0187 - val_loss: 0.0178\n",
      "Epoch 88/100\n",
      "34300/34300 [==============================] - 32s - loss: 0.0185 - val_loss: 0.0178\n",
      "Epoch 89/100\n",
      "34300/34300 [==============================] - 32s - loss: 0.0185 - val_loss: 0.0179\n",
      "Epoch 90/100\n",
      "34300/34300 [==============================] - 32s - loss: 0.0184 - val_loss: 0.0182\n",
      "Epoch 91/100\n",
      "34300/34300 [==============================] - 31s - loss: 0.0185 - val_loss: 0.0178\n",
      "Epoch 92/100\n",
      "34300/34300 [==============================] - 32s - loss: 0.0184 - val_loss: 0.0176\n",
      "Epoch 93/100\n",
      "34300/34300 [==============================] - 32s - loss: 0.0183 - val_loss: 0.0177\n",
      "Epoch 94/100\n",
      "34300/34300 [==============================] - 32s - loss: 0.0183 - val_loss: 0.0177\n",
      "Epoch 95/100\n",
      "34300/34300 [==============================] - 32s - loss: 0.0182 - val_loss: 0.0175\n",
      "Epoch 96/100\n",
      "34300/34300 [==============================] - 31s - loss: 0.0181 - val_loss: 0.0175\n",
      "Epoch 97/100\n",
      "34300/34300 [==============================] - 32s - loss: 0.0182 - val_loss: 0.0173\n",
      "Epoch 98/100\n",
      "34300/34300 [==============================] - 32s - loss: 0.0181 - val_loss: 0.0174\n",
      "Epoch 99/100\n",
      "34300/34300 [==============================] - 32s - loss: 0.0181 - val_loss: 0.0174\n",
      "Epoch 100/100\n",
      "34300/34300 [==============================] - 32s - loss: 0.0180 - val_loss: 0.0175\n"
     ]
    }
   ],
   "source": [
    "#Now let us train our autoencoder model.\n",
    "train_history = autoencoder.fit(train_x, train_x, epochs=100, batch_size=2048, validation_data=(val_x, val_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_auto_train = encoder.predict(train_x)\n",
    "pred_auto = encoder.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34300, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_auto_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14700, 10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_auto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = Sequential()\n",
    "mlp.add(Dense(1000,input_dim = 10,activation='sigmoid'))\n",
    "mlp.add(Dense(500,activation='relu'))\n",
    "mlp.add(Dense(200,activation='relu'))\n",
    "mlp.add(Dense(10,activation='softmax'))\n",
    "mlp.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 1000)              11000     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 613,710\n",
      "Trainable params: 613,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = keras.utils.to_categorical(train_y,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34300, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30870 samples, validate on 3430 samples\n",
      "Epoch 1/50\n",
      "30870/30870 [==============================] - 23s - loss: 0.8906 - acc: 0.6786 - val_loss: 0.5082 - val_acc: 0.8344\n",
      "Epoch 2/50\n",
      "30870/30870 [==============================] - 23s - loss: 0.4761 - acc: 0.8408 - val_loss: 0.4537 - val_acc: 0.8525\n",
      "Epoch 3/50\n",
      "30870/30870 [==============================] - 23s - loss: 0.3836 - acc: 0.8760 - val_loss: 0.3433 - val_acc: 0.8843\n",
      "Epoch 4/50\n",
      "30870/30870 [==============================] - 23s - loss: 0.3394 - acc: 0.8915 - val_loss: 0.4198 - val_acc: 0.8682\n",
      "Epoch 5/50\n",
      "30870/30870 [==============================] - 23s - loss: 0.3095 - acc: 0.8998 - val_loss: 0.3287 - val_acc: 0.8924\n",
      "Epoch 6/50\n",
      "30870/30870 [==============================] - 23s - loss: 0.3004 - acc: 0.9014 - val_loss: 0.2915 - val_acc: 0.9096\n",
      "Epoch 7/50\n",
      "30870/30870 [==============================] - 23s - loss: 0.2880 - acc: 0.9063 - val_loss: 0.2538 - val_acc: 0.9184\n",
      "Epoch 8/50\n",
      "30870/30870 [==============================] - 23s - loss: 0.2706 - acc: 0.9121 - val_loss: 0.3413 - val_acc: 0.8913\n",
      "Epoch 9/50\n",
      "30870/30870 [==============================] - 23s - loss: 0.2505 - acc: 0.9201 - val_loss: 0.2680 - val_acc: 0.9143\n",
      "Epoch 10/50\n",
      "30870/30870 [==============================] - 23s - loss: 0.2435 - acc: 0.9215 - val_loss: 0.2529 - val_acc: 0.9227\n",
      "Epoch 11/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.2252 - acc: 0.9274 - val_loss: 0.2493 - val_acc: 0.9198\n",
      "Epoch 12/50\n",
      "30870/30870 [==============================] - 23s - loss: 0.2122 - acc: 0.9305 - val_loss: 0.2384 - val_acc: 0.9274\n",
      "Epoch 13/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.2071 - acc: 0.9343 - val_loss: 0.2135 - val_acc: 0.9344\n",
      "Epoch 14/50\n",
      "30870/30870 [==============================] - 23s - loss: 0.1945 - acc: 0.9393 - val_loss: 0.2312 - val_acc: 0.9289\n",
      "Epoch 15/50\n",
      "30870/30870 [==============================] - 23s - loss: 0.1861 - acc: 0.9402 - val_loss: 0.1975 - val_acc: 0.9376\n",
      "Epoch 16/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1786 - acc: 0.9436 - val_loss: 0.1942 - val_acc: 0.9414\n",
      "Epoch 17/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1727 - acc: 0.9448 - val_loss: 0.1803 - val_acc: 0.9455\n",
      "Epoch 18/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1691 - acc: 0.9440 - val_loss: 0.1920 - val_acc: 0.9405\n",
      "Epoch 19/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1650 - acc: 0.9471 - val_loss: 0.2147 - val_acc: 0.9356\n",
      "Epoch 20/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1605 - acc: 0.9477 - val_loss: 0.2044 - val_acc: 0.9420\n",
      "Epoch 21/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1588 - acc: 0.9492 - val_loss: 0.2195 - val_acc: 0.9329\n",
      "Epoch 22/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1522 - acc: 0.9505 - val_loss: 0.1673 - val_acc: 0.9519\n",
      "Epoch 23/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1458 - acc: 0.9533 - val_loss: 0.1687 - val_acc: 0.9466\n",
      "Epoch 24/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1445 - acc: 0.9523 - val_loss: 0.1760 - val_acc: 0.9475\n",
      "Epoch 25/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1422 - acc: 0.9539 - val_loss: 0.1717 - val_acc: 0.9429\n",
      "Epoch 26/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1390 - acc: 0.9555 - val_loss: 0.1748 - val_acc: 0.9499\n",
      "Epoch 27/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1371 - acc: 0.9553 - val_loss: 0.1696 - val_acc: 0.9528\n",
      "Epoch 28/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1351 - acc: 0.9569 - val_loss: 0.1680 - val_acc: 0.9525\n",
      "Epoch 29/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1293 - acc: 0.9584 - val_loss: 0.1601 - val_acc: 0.9551\n",
      "Epoch 30/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1289 - acc: 0.9580 - val_loss: 0.1653 - val_acc: 0.9513\n",
      "Epoch 31/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1283 - acc: 0.9573 - val_loss: 0.1725 - val_acc: 0.9534\n",
      "Epoch 32/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1252 - acc: 0.9586 - val_loss: 0.1562 - val_acc: 0.9574\n",
      "Epoch 33/50\n",
      "30870/30870 [==============================] - 24s - loss: 0.1234 - acc: 0.9598 - val_loss: 0.1492 - val_acc: 0.9574\n",
      "Epoch 34/50\n",
      "30870/30870 [==============================] - 23s - loss: 0.1198 - acc: 0.9603 - val_loss: 0.1580 - val_acc: 0.9566\n",
      "Epoch 35/50\n",
      "30870/30870 [==============================] - 23s - loss: 0.1160 - acc: 0.9615 - val_loss: 0.1601 - val_acc: 0.9548\n",
      "Epoch 36/50\n",
      "30870/30870 [==============================] - 25s - loss: 0.1167 - acc: 0.9617 - val_loss: 0.1591 - val_acc: 0.9534\n",
      "Epoch 37/50\n",
      "30870/30870 [==============================] - 27s - loss: 0.1139 - acc: 0.9617 - val_loss: 0.1667 - val_acc: 0.9542\n",
      "Epoch 38/50\n",
      "30870/30870 [==============================] - 25s - loss: 0.1137 - acc: 0.9620 - val_loss: 0.1489 - val_acc: 0.9545\n",
      "Epoch 39/50\n",
      "30870/30870 [==============================] - 27s - loss: 0.1110 - acc: 0.9642 - val_loss: 0.1465 - val_acc: 0.9577\n",
      "Epoch 40/50\n",
      "30870/30870 [==============================] - 26s - loss: 0.1088 - acc: 0.9631 - val_loss: 0.1513 - val_acc: 0.9592\n",
      "Epoch 41/50\n",
      "30870/30870 [==============================] - 26s - loss: 0.1090 - acc: 0.9630 - val_loss: 0.1622 - val_acc: 0.9522\n",
      "Epoch 42/50\n",
      "30870/30870 [==============================] - 27s - loss: 0.1065 - acc: 0.9645 - val_loss: 0.1464 - val_acc: 0.9560\n",
      "Epoch 43/50\n",
      "30870/30870 [==============================] - 26s - loss: 0.1074 - acc: 0.9649 - val_loss: 0.1569 - val_acc: 0.9563\n",
      "Epoch 44/50\n",
      "30870/30870 [==============================] - 22s - loss: 0.1032 - acc: 0.9645 - val_loss: 0.1544 - val_acc: 0.9560\n",
      "Epoch 45/50\n",
      "30870/30870 [==============================] - 21s - loss: 0.1038 - acc: 0.9660 - val_loss: 0.1693 - val_acc: 0.9507\n",
      "Epoch 46/50\n",
      "30870/30870 [==============================] - 21s - loss: 0.1035 - acc: 0.9659 - val_loss: 0.1565 - val_acc: 0.9534\n",
      "Epoch 47/50\n",
      "30870/30870 [==============================] - 21s - loss: 0.0991 - acc: 0.9672 - val_loss: 0.1631 - val_acc: 0.9519\n",
      "Epoch 48/50\n",
      "30870/30870 [==============================] - 21s - loss: 0.0988 - acc: 0.9668 - val_loss: 0.1610 - val_acc: 0.9566\n",
      "Epoch 49/50\n",
      "30870/30870 [==============================] - 21s - loss: 0.0992 - acc: 0.9663 - val_loss: 0.1471 - val_acc: 0.9601\n",
      "Epoch 50/50\n",
      "30870/30870 [==============================] - 21s - loss: 0.0963 - acc: 0.9682 - val_loss: 0.1683 - val_acc: 0.9536\n"
     ]
    }
   ],
   "source": [
    "mlp_train = mlp.fit(pred_auto_train,train_y,epochs=50,verbose=1,batch_size=32,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14700/14700 [==============================] - 1s     \n"
     ]
    }
   ],
   "source": [
    "preds =mlp.predict_classes(pred_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1443,    0,    4,    0,    0,    5,    2,    0,   10,    6],\n",
       "       [   0, 1581,    4,    2,    1,    2,    1,    3,   16,    3],\n",
       "       [  11,   18, 1373,   27,    1,    3,    0,    9,   36,    3],\n",
       "       [   0,    4,    2, 1412,    0,   30,    0,    7,   69,    4],\n",
       "       [   2,    1,    3,    1, 1344,    3,    5,    1,   10,   66],\n",
       "       [   4,    0,    0,   29,    0, 1257,   17,    0,   22,    7],\n",
       "       [   2,    2,    0,    1,    3,    7, 1399,    0,    9,    1],\n",
       "       [   1,    3,    9,    9,    8,    2,    1, 1458,    6,   24],\n",
       "       [   4,    7,    0,   13,    0,   11,    1,    0, 1375,   10],\n",
       "       [   3,    1,    4,   15,    6,    6,    0,   12,   10, 1413]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(val_y,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95612244897959187"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(val_y,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_auto_test = encoder.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20864/21000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "test_preds = mlp.predict_classes(pred_auto_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 9, ..., 6, 6, 2], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(test_preds,)\n",
    "output.to_csv( \"preds.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cnn\n",
    "from keras.layers import "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
